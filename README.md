
<div align="center">

# ğŸ§  Local Multimodal AI Agent
### æœ¬åœ°å¤šæ¨¡æ€æ™ºèƒ½çŸ¥è¯†åº“åŠ©æ‰‹

[English](README_EN.md) | [ç®€ä½“ä¸­æ–‡](README.md)

![Python Version](https://img.shields.io/badge/Python-3.10-blue?style=for-the-badge&logo=python&logoColor=white)
![Model](https://img.shields.io/badge/Model-CLIP_%2B_MiniLM-ff69b4?style=for-the-badge&logo=openai&logoColor=white)
![DB](https://img.shields.io/badge/Vector_DB-ChromaDB-green?style=for-the-badge&logo=databricks&logoColor=white)
![Status](https://img.shields.io/badge/Status-Assignment_Completed-success?style=for-the-badge)

<p align="center">
  <strong>åŸºäº RAG ä¸ å¤šæ¨¡æ€å¤§æ¨¡å‹ çš„æœ¬åœ°åŒ–æ™ºèƒ½æ–‡ä»¶ç®¡ç†ç³»ç»Ÿ</strong><br>
  æ— éœ€è”ç½‘ Â· éšç§å®‰å…¨ Â· è¯­ä¹‰ç†è§£ Â· è·¨æ¨¡æ€æ£€ç´¢
</p>

</div>

---

## ğŸ“– ç›®å½• (Table of Contents)

- [é¡¹ç›®ç®€ä»‹](#-é¡¹ç›®ç®€ä»‹-introduction)
- [ç³»ç»Ÿæ¶æ„](#-ç³»ç»Ÿæ¶æ„-architecture)
- [æ ¸å¿ƒåŠŸèƒ½](#-æ ¸å¿ƒåŠŸèƒ½-features)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹-quick-start)
- [å®éªŒæŠ¥å‘Šä¸æ€§èƒ½è¯„ä¼°](#-å®éªŒæŠ¥å‘Šä¸æ€§èƒ½è¯„ä¼°-performance-evaluation)
    - [å®éªŒ 1: é›¶æ ·æœ¬æ™ºèƒ½åˆ†ç±» (Zero-Shot Classification)](#1-æ™ºèƒ½åˆ†ç±»é²æ£’æ€§æµ‹è¯•)
    - [å®éªŒ 2: æ·±åº¦è¯­ä¹‰æ£€ç´¢ (RAG)](#2-æ·±åº¦è¯­ä¹‰æ£€ç´¢-rag-æµ‹è¯•)
    - [å®éªŒ 3: è·¨æ¨¡æ€ä»¥æ–‡æœå›¾ (Text-to-Image)](#3-è·¨æ¨¡æ€ä»¥æ–‡æœå›¾æµ‹è¯•)
- [é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„-project-structure)
- [è‡´è°¢](#-è‡´è°¢-acknowledgements)

---

## ğŸ’¡ é¡¹ç›®ç®€ä»‹ (Introduction)

**Local Multimodal AI Agent** æ˜¯ä¸€ä¸ªè½»é‡çº§ä½†åœ¨ç®—æ³•ä¸Šå…ˆè¿›çš„æœ¬åœ°æ™ºèƒ½åŠ©æ‰‹ã€‚æ—¨åœ¨è§£å†³éç»“æ„åŒ–æ•°æ®ï¼ˆPDF æ–‡çŒ®ã€å›¾åƒç´ æï¼‰ç®¡ç†éš¾ã€æ£€ç´¢éš¾çš„é—®é¢˜ã€‚

ä¸åŒäºä¼ ç»Ÿçš„æ–‡ä»¶ååŒ¹é…ï¼Œæœ¬é¡¹ç›®åˆ©ç”¨ **Sentence-Transformers** å’Œ **CLIP** æ¨¡å‹ï¼Œå°†æ‰€æœ‰æœ¬åœ°æ•°æ®æ˜ å°„åˆ°é«˜ç»´å‘é‡ç©ºé—´ï¼Œä»è€Œå®ç°ï¼š
1.  **æœºå™¨ç†è§£**ï¼šAI çœŸæ­£è¯»æ‡‚äº†è®ºæ–‡æ‘˜è¦å’Œå›¾ç‰‡å†…å®¹ã€‚
2.  **è‡ªåŠ¨åŒ–**ï¼šæ ¹æ®è¯­ä¹‰ç†è§£è‡ªåŠ¨æ•´ç†æ‚ä¹±çš„æ–‡ä»¶ã€‚
3.  **è‡ªç„¶äº¤äº’**ï¼šåƒä¸äººäº¤è°ˆä¸€æ ·æœç´¢ä½ çš„æœ¬åœ°çŸ¥è¯†åº“ã€‚

---

## âš™ï¸ ç³»ç»Ÿæ¶æ„ (Architecture)

æœ¬é¡¹ç›®é‡‡ç”¨äº†ç»å…¸çš„ **RAG (Retrieval-Augmented Generation)** æ¶æ„å˜ä½“ä¸åŒå¡”å¤šæ¨¡æ€æ¨¡å‹ï¼š

```mermaid
graph LR
    A[ç”¨æˆ·è¾“å…¥ User Input] --> B{ä»»åŠ¡åˆ†å‘ Router}
    
    subgraph "Document Pipeline (Text)"
    C1[PDF Parsing] --> C2[MiniLM Embedding] --> C3[(ChromaDB - Papers)]
    end
    
    subgraph "Visual Pipeline (Image)"
    D1[Image Loading] --> D2[CLIP Image Encoder] --> D3[(ChromaDB - Images)]
    end
    
    B -- "Search Paper" --> E1[Query Embedding] --> C3
    B -- "Search Image" --> E2[CLIP Text Encoder] --> D3
    B -- "Add Paper" --> C1
    
    C3 --> F[è¯­ä¹‰ç›¸ä¼¼åº¦æ’åº]
    D3 --> F
    F --> G[æœ€ç»ˆç»“æœ Output]

```

---

## âœ¨ æ ¸å¿ƒåŠŸèƒ½ (Features)

| æ¨¡å— | åŠŸèƒ½ç‰¹æ€§ | æè¿° |
| --- | --- | --- |
| **ğŸ“„ æ–‡çŒ®æ™ºèƒ½** | **Zero-Shot è‡ªåŠ¨åˆ†ç±»** | åŸºäºå‘é‡ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œè‡ªåŠ¨å°†è®ºæ–‡å½’æ¡£è‡³ `EdgeAI`, `CV`, `LLM` ç­‰æ–‡ä»¶å¤¹ï¼Œæ— éœ€è®­ç»ƒã€‚ |
|  | **æ·±åº¦è¯­ä¹‰æ£€ç´¢** | æ”¯æŒ "How does Transformer work?" ç­‰è‡ªç„¶è¯­è¨€æé—®ï¼Œç²¾å‡†å®šä½æŠ€æœ¯ç»†èŠ‚ã€‚ |
| **ğŸ–¼ï¸ è§†è§‰æ™ºèƒ½** | **Text-to-Image æœå›¾** | åˆ©ç”¨ CLIP æ¨¡å‹å®ç°â€œä»¥æ–‡æœå›¾â€ï¼Œæ”¯æŒå¦‚ "A cat in the sunset" çš„æè¿°æ€§æœç´¢ã€‚ |
| **ğŸ”’ éšç§ä¸æ€§èƒ½** | **100% æœ¬åœ°åŒ–** | æ•°æ®ä¸å‡ºåŸŸï¼Œä¿æŠ¤éšç§ã€‚åŸºäº ChromaDB å®ç°æ¯«ç§’çº§å“åº”ã€‚ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ (Quick Start)

### 1. ç¯å¢ƒå‡†å¤‡

æœ¬é¡¹ç›®åŸºäº Python 3.10 å¼€å‘ï¼Œå»ºè®®ä½¿ç”¨ Conda ç®¡ç†ç¯å¢ƒã€‚

```bash
# åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
conda create -n ai_agent python=3.10
conda activate ai_agent

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

```

### 2. åˆå§‹åŒ–æ•°æ®

åœ¨é¦–æ¬¡è¿è¡Œå‰ï¼Œè®© AI æ‰«æå¹¶â€œå­¦ä¹ â€æœ¬åœ°å›¾ç‰‡åº“çš„ç‰¹å¾ï¼š

```bash
python main.py index_images ./images

```

### 3. è¿è¡Œæ ¸å¿ƒæŒ‡ä»¤

**ğŸ“š æ·»åŠ å¹¶è‡ªåŠ¨åˆ†ç±»è®ºæ–‡**

```bash
python main.py add_paper ./papers/your_paper.pdf --topics "Topic_A,Topic_B,Topic_C"

```

**ğŸ” æœç´¢è®ºæ–‡**

```bash
python main.py search_paper "What is the core contribution of this paper?"

```

**ğŸ¨ æœç´¢å›¾ç‰‡**

```bash
python main.py search_image "A futuristic city"

```

---

## ğŸ“Š å®éªŒæŠ¥å‘Šä¸æ€§èƒ½è¯„ä¼° (Performance Evaluation)

> æœ¬èŠ‚å±•ç¤ºäº†åŸºäºçœŸå®å­¦æœ¯è®ºæ–‡é›†ï¼ˆAirFL, VIGIL ç­‰ï¼‰çš„å®æµ‹è¡¨ç°ï¼ŒéªŒè¯äº†ç³»ç»Ÿçš„æ™ºèƒ½ç¨‹åº¦ã€‚

### 1. æ™ºèƒ½åˆ†ç±»é²æ£’æ€§æµ‹è¯•

ä¸ºäº†éªŒè¯ AI æ˜¯å¦å…·å¤‡çœŸå®çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼ˆè€ŒééšæœºçŒœæµ‹ï¼‰ï¼Œæˆ‘ä»¬è®¾è®¡äº† **"ç»Ÿä¸€æ··æ·†é¡¹æµ‹è¯•" (Unified Confusion Test)**ã€‚
å³ï¼šå¯¹ä¸åŒé¢†åŸŸçš„è®ºæ–‡ï¼Œæä¾›**å®Œå…¨ç›¸åŒ**çš„å€™é€‰ä¸»é¢˜åˆ—è¡¨ï¼Œè§‚å¯Ÿ AI èƒ½å¦ç²¾å‡†å‘½ä¸­ã€‚

* **æµ‹è¯•æ ·æœ¬**:
* Paper A: `AirFL (Signal Processing)`
* Paper B: `VIGIL (LLM Agent)`


* **ç»Ÿä¸€å€™é€‰æ± **: `"Edge_Computing, LLM_Agents, Computer_Vision"`

| è®ºæ–‡æ–‡ä»¶ | çœŸå®é¢†åŸŸ | AI é¢„æµ‹åˆ†ç±» | ç½®ä¿¡åº¦ | ç»“æœ |
| --- | --- | --- | --- | --- |
| `2512.03719v1.pdf` | Signal Processing | **Edge_Computing** | `0.40` | âœ… Pass |
| `2512.07094v2.pdf` | LLM Agent | **LLM_Agents** | `0.47` | âœ… Pass |

<details>
<summary>ğŸ”» ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†ç»ˆç«¯è¿è¡Œæ—¥å¿— (Screenshot)</summary>

> **[è¯·åœ¨æ­¤å¤„æ’å…¥ä½ è¿è¡Œ add_paper åˆ†ç±»æˆåŠŸçš„æˆªå›¾]**
> *å›¾ 1: ç³»ç»ŸæˆåŠŸæ ¹æ®è¯­ä¹‰å°†ä¸¤ç¯‡è®ºæ–‡åˆ†å…¥ä¸åŒæ–‡ä»¶å¤¹ï¼Œå°½ç®¡å€™é€‰åˆ—è¡¨å®Œå…¨ç›¸åŒã€‚*

</details>

---

### 2. æ·±åº¦è¯­ä¹‰æ£€ç´¢ (RAG) æµ‹è¯•

éªŒè¯ç³»ç»Ÿæ˜¯å¦èƒ½å›ç­”å…·ä½“çš„å­¦æœ¯é—®é¢˜ï¼Œå¹¶åŒºåˆ†å¹²æ‰°é¡¹ã€‚

**æµ‹è¯• Query**: `"How does AirFL reduce latency and bandwidth consumption?"`

* **é¢„æœŸ**: ç³»ç»Ÿåº”æ£€ç´¢åˆ° AirFL ç›¸å…³è®ºæ–‡ï¼Œè€Œé Agent ç›¸å…³è®ºæ–‡ã€‚
* **Top-2 å¬å›ç»“æœ**:

```text
[1] 2512.03719v1.pdf (AirFL)  | Score: 0.3557 (High Relevance) ğŸŒŸ
[2] 2512.07094v2.pdf (VIGIL)  | Score: -0.1366 (Not Relevant)

```

**åˆ†æ**: åˆ†æ•°å·®å¼‚æ˜¾è‘—ï¼ˆ>0.4 gapï¼‰ï¼Œè¯æ˜å‘é‡æ•°æ®åº“æˆåŠŸæ•æ‰äº† "Latency" å’Œ "Bandwidth" ä¸ AirFL è®ºæ–‡çš„å¼ºè¯­ä¹‰å…³è”ã€‚

<details>
<summary>ğŸ”» ç‚¹å‡»æŸ¥çœ‹æœç´¢ç»“æœæˆªå›¾</summary>

> **[è¯·åœ¨æ­¤å¤„æ’å…¥ search_paper ç»“æœæˆªå›¾]**

</details>

---

### 3. è·¨æ¨¡æ€ä»¥æ–‡æœå›¾æµ‹è¯•

æµ‹è¯•å¤šæ¨¡æ€ CLIP æ¨¡å‹çš„å¯¹é½èƒ½åŠ›ã€‚

**æµ‹è¯• Query**: `"A cat"` (å¯»æ‰¾ä¸€å¼ çŒ«çš„ç…§ç‰‡)

* **å›¾ç‰‡åº“**: åŒ…å«å»ºç­‘(Picture2)ã€çŒ«(Picture3)ã€å…¶ä»–(Picture1)ã€‚
* **æ£€ç´¢ç»“æœ**:

```text
[1] Picture3.jpeg (çœŸå®çŒ«å›¾) | åŒ¹é…åº¦: 0.2770 ğŸŒŸ
[2] Picture2.jpg  (å¹²æ‰°é¡¹)   | åŒ¹é…åº¦: 0.1852

```

**ç»“è®º**: æ¨¡å‹æˆåŠŸå®ç°äº†æ–‡æœ¬åˆ°å›¾åƒçš„è·¨æ¨¡æ€æ˜ å°„ã€‚

<details>
<summary>ğŸ”» ç‚¹å‡»æŸ¥çœ‹æœå›¾ç»“æœæˆªå›¾</summary>

> **[è¯·åœ¨æ­¤å¤„æ’å…¥ search_image ç»“æœæˆªå›¾]**

</details>

---

## ğŸ“‚ é¡¹ç›®ç»“æ„ (Project Structure)

```powershell
MyAI_Agent/
â”œâ”€â”€ ğŸ“‚ db/                  # ChromaDB å‘é‡æ•°æ®åº“ (è‡ªåŠ¨æŒä¹…åŒ–)
â”œâ”€â”€ ğŸ“‚ images/              # æœ¬åœ°å›¾åƒæ•°æ®é›†
â”œâ”€â”€ ğŸ“‚ papers/              # è®ºæ–‡å­˜å‚¨åº“
â”‚   â”œâ”€â”€ ğŸ“‚ Edge_Computing/  # [AIè‡ªåŠ¨ç”Ÿæˆ] è¾¹ç¼˜è®¡ç®—ç±»è®ºæ–‡
â”‚   â””â”€â”€ ğŸ“‚ LLM_Agents/      # [AIè‡ªåŠ¨ç”Ÿæˆ] å¤§æ¨¡å‹ç±»è®ºæ–‡
â”œâ”€â”€ main.py                 # ğŸš€ ç³»ç»Ÿä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ requirements.txt        # ä¾èµ–é…ç½®æ–‡ä»¶
â””â”€â”€ README.md               # é¡¹ç›®æ–‡æ¡£

```

---

## ğŸ› ï¸ æŠ€æœ¯æ ˆè¯¦æƒ… (Tech Stack Details)

* **Embedding Model**: `sentence-transformers/all-MiniLM-L6-v2`
* é€‰ç”¨ç†ç”±ï¼šåœ¨æ€§èƒ½ä¸é€Ÿåº¦ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡ï¼Œç”Ÿæˆ 384 ç»´ç¨ å¯†å‘é‡ã€‚


* **Multimodal Model**: `openai/clip-vit-base-patch32`
* é€‰ç”¨ç†ç”±ï¼šä¸šç•Œæ ‡å‡†çš„å›¾æ–‡å¯¹é½æ¨¡å‹ï¼Œæ”¯æŒ Zero-Shot å›¾åƒæ£€ç´¢ã€‚


* **Vector Database**: `ChromaDB`
* é€‰ç”¨ç†ç”±ï¼šè½»é‡çº§ã€æ— éœ€ Dockerã€æ”¯æŒå…ƒæ•°æ®è¿‡æ»¤ï¼Œéå¸¸é€‚åˆæœ¬åœ° Agentã€‚



---

<div align="center">

**Created with â¤ï¸ for this Course Assignment**





*2025 Submission*

</div>


